{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f6ed8c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.io as tvio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d848c",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d865be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=123):\n",
    "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # fixed 256x256 → faster\n",
    "set_seed(42)\n",
    "\n",
    "def psnr(x: torch.Tensor, y: torch.Tensor, eps=1e-8) -> float:\n",
    "    mse = F.mse_loss(x, y).item()\n",
    "    if mse <= eps: return 99.0\n",
    "    return 10.0 * math.log10(1.0 / mse)\n",
    "\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "def check_sample(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return True\n",
    "    try:\n",
    "        _ = torch.as_tensor(x)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc8305",
   "metadata": {},
   "source": [
    "## Build Dataset Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c7eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyCleanDataset(Dataset):\n",
    "    def __init__(self, root: str, size: Optional[int]=None):\n",
    "        self.root = Path(root)\n",
    "        self.clean_dir = self.root / \"clean\"\n",
    "        self.add_dir = self.root / \"additive\"\n",
    "        self.mul_dir  = self.root / \"multiplicative\"\n",
    "        assert self.clean_dir.is_dir() and self.add_dir.is_dir() and self.mul_dir.is_dir(), \"Folders missing\"\n",
    "\n",
    "        self.clean_files = sorted(self.clean_dir.glob(\"img_*.png\"))\n",
    "        if size is not None:\n",
    "            self.clean_files = self.clean_files[:size]\n",
    "\n",
    "        self.add_map: Dict[str, List[Path]] = {}\n",
    "        self.mul_map: Dict[str, List[Path]] = {}\n",
    "\n",
    "        for cf in self.clean_files:\n",
    "            m = re.match(r\"img_(\\d+)\\.png\", cf.name)\n",
    "            if not m: \n",
    "                continue\n",
    "            cid = m.group(1)\n",
    "            adds = sorted(self.add_dir.glob(f\"img_{cid}_add_*.png\"))\n",
    "            if adds: self.add_map[cid] = adds\n",
    "            muls = sorted(self.mul_dir.glob(f\"img_{cid}_mul_*.png\"))\n",
    "            if not muls:\n",
    "                muls = sorted(self.mul_dir.glob(f\"image_{cid}_mul_*.png\"))\n",
    "            if muls: self.mul_map[cid] = muls\n",
    "\n",
    "        self.ids = [re.match(r\"img_(\\d+)\\.png\", p.name).group(1)\n",
    "                    for p in self.clean_files\n",
    "                    if (re.match(r\"img_(\\d+)\\.png\", p.name)\n",
    "                        and (self.add_map.get(re.match(r\"img_(\\d+)\\.png\", p.name).group(1))\n",
    "                             or self.mul_map.get(re.match(r\"img_(\\d+)\\.png\", p.name).group(1))))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @staticmethod\n",
    "    def _read_rgb01(path: Path) -> torch.Tensor:\n",
    "        t = tvio.read_image(str(path))\n",
    "        return t.float().div_(255.0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cid = self.ids[idx]\n",
    "        clean_path = self.clean_dir / f\"img_{cid}.png\"\n",
    "\n",
    "        choices = []\n",
    "        if cid in self.add_map: choices.append(\"add\")\n",
    "        if cid in self.mul_map: choices.append(\"mul\")\n",
    "        noise_type = random.choice(choices)\n",
    "\n",
    "        if noise_type == \"add\":\n",
    "            noisy_path = random.choice(self.add_map[cid]); noise_label = 0\n",
    "        else:\n",
    "            noisy_path = random.choice(self.mul_map[cid]); noise_label = 1\n",
    "\n",
    "        clean_t = self._read_rgb01(clean_path)\n",
    "        noisy_t = self._read_rgb01(noisy_path)\n",
    "        return noisy_t, clean_t, noise_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82736685",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchA_Filters(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=11, padding=5, bias=True, groups=3)\n",
    "        nn.init.kaiming_normal_(self.conv.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, use_bn=True, p_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.use_proj = (in_ch != 32)\n",
    "        self.conv1 = nn.Conv2d(in_ch, 32, 3, padding=1, bias=not use_bn)\n",
    "        self.bn1   = nn.BatchNorm2d(32) if use_bn else nn.Identity()\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1, bias=not use_bn)\n",
    "        self.bn2   = nn.BatchNorm2d(32) if use_bn else nn.Identity()\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.drop  = nn.Dropout2d(p_drop) if p_drop > 0 else nn.Identity()\n",
    "        self.proj  = nn.Conv2d(in_ch, 32, 1) if self.use_proj else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out); out = self.drop(out)\n",
    "        out = self.conv2(out); out = self.bn2(out)\n",
    "        if self.use_proj: identity = self.proj(identity)\n",
    "        out = self.relu(out + identity)\n",
    "        return out\n",
    "\n",
    "class BranchB_Weights(nn.Module):\n",
    "    def __init__(self, use_bn=True, p_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.block1 = ResBlock(3, use_bn=use_bn, p_drop=p_drop)\n",
    "        self.block2 = ResBlock(32, use_bn=use_bn, p_drop=p_drop)\n",
    "        self.block3 = ResBlock(32, use_bn=use_bn, p_drop=p_drop)\n",
    "        self.to8    = nn.Conv2d(32, 8, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x); out = self.block2(out); out = self.block3(out)\n",
    "        logits = self.to8(out)\n",
    "        weights = F.softmax(logits, dim=1)\n",
    "        return weights\n",
    "\n",
    "class EdgePreservingDenoiser(nn.Module):\n",
    "    def __init__(self, use_bn=True, p_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.branchA = BranchA_Filters()\n",
    "        self.branchB = BranchB_Weights(use_bn=use_bn, p_drop=p_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        A = self.branchA(x)\n",
    "        W = self.branchB(x)\n",
    "\n",
    "        A_R = A[:, 0:8,  :, :]\n",
    "        A_G = A[:, 8:16, :, :]\n",
    "        A_B = A[:,16:24, :, :]\n",
    "\n",
    "        R = (A_R * W).sum(1, keepdim=True)\n",
    "        G = (A_G * W).sum(1, keepdim=True)\n",
    "        B = (A_B * W).sum(1, keepdim=True)\n",
    "        return torch.cat([R,G,B], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e282a",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a95a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "train_ds = NoisyCleanDataset(\"dataset\", size=8192)\n",
    "train_dl = DataLoader(\n",
    "    train_ds, batch_size=4, shuffle=True,\n",
    "    num_workers=8, pin_memory=True,\n",
    "    persistent_workers=True, prefetch_factor=4, drop_last=True\n",
    ")\n",
    "\n",
    "model = EdgePreservingDenoiser(use_bn=True, p_drop=0.0).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1701d5",
   "metadata": {},
   "source": [
    "## Check sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity OK. Loss: 0.1842 | PSNR: 7.35 dB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bad_indices = []\n",
    "for i in range(min(32, len(train_ds) if 'train_ds' in globals() else len(ds))):\n",
    "    try:\n",
    "        noisy_i, clean_i, _ = (train_ds[i] if 'train_ds' in globals() else ds[i])\n",
    "        assert check_sample(noisy_i), \"noisy sample not tensor/convertible\"\n",
    "        assert check_sample(clean_i), \"clean sample not tensor/convertible\"\n",
    "    except Exception as e:\n",
    "        bad_indices.append((i, repr(e)))\n",
    "\n",
    "if bad_indices:\n",
    "    print(\"⚠️ Dataset errors at indices:\", bad_indices[:5], \"…\")\n",
    "    raise RuntimeError(\"Fix dataset item(s) above (e.g., path missing, shape mismatch, dtype issue).\")\n",
    "\n",
    "# --- 2) Rebuild DataLoader WITHOUT multiprocessing (Jupyter/macOS safe) ---\n",
    "def make_loader(dataset, device, batch_size=4):\n",
    "    use_cuda = (device.type == \"cuda\")\n",
    "    return DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0,              # <- critical fix in notebooks/macOS\n",
    "        pin_memory=use_cuda,        # only helpful on CUDA\n",
    "        persistent_workers=False,   # only valid with num_workers>0\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "# Prefer train_ds if you have separate splits; else use ds\n",
    "active_ds = train_ds if 'train_ds' in globals() else ds\n",
    "train_dl = make_loader(active_ds, device, batch_size=4)\n",
    "\n",
    "# --- 3) One sanity training step ---\n",
    "model.to(device).train()\n",
    "\n",
    "noisy, clean, _ = next(iter(train_dl))\n",
    "noisy = noisy.to(device, non_blocking=True)\n",
    "clean = clean.to(device, non_blocking=True)\n",
    "\n",
    "pred = model(noisy)\n",
    "loss = loss_fn(pred, clean)\n",
    "\n",
    "opt.zero_grad(set_to_none=True)\n",
    "loss.backward()\n",
    "opt.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # simple PSNR over batch\n",
    "    def _psnr(a, b, eps=1e-8):\n",
    "        mse = torch.mean((a - b) ** 2).clamp_min(eps)\n",
    "        return 10.0 * torch.log10(1.0 / mse)  # assumes inputs in [0,1]; adjust if needed\n",
    "    bpsnr = _psnr(pred, clean).item()\n",
    "\n",
    "if device.type == \"mps\":\n",
    "    torch.mps.synchronize()\n",
    "\n",
    "print(f\"Sanity OK. Loss: {float(loss):.4f} | PSNR: {bpsnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38e47b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ec795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 2048/2048 [11:13<00:00,  3.04it/s, it=2048/2048, loss=0.0025, avg=0.0046, psnr=26.73 dB, avg_psnr=24.93 dB, gstep=2048, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] avg loss 0.0046 | avg PSNR 24.93 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 2048/2048 [09:53<00:00,  3.45it/s, it=2048/2048, loss=0.0020, avg=0.0027, psnr=27.10 dB, avg_psnr=27.50 dB, gstep=4096, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] avg loss 0.0027 | avg PSNR 27.50 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 2048/2048 [09:47<00:00,  3.49it/s, it=2048/2048, loss=0.0016, avg=0.0022, psnr=28.39 dB, avg_psnr=28.40 dB, gstep=6144, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] avg loss 0.0022 | avg PSNR 28.40 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 2048/2048 [10:04<00:00,  3.39it/s, it=2048/2048, loss=0.0008, avg=0.0022, psnr=30.87 dB, avg_psnr=28.73 dB, gstep=8192, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] avg loss 0.0022 | avg PSNR 28.73 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 2048/2048 [10:48<00:00,  3.16it/s, it=2048/2048, loss=0.0014, avg=0.0020, psnr=29.66 dB, avg_psnr=29.11 dB, gstep=10240, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] avg loss 0.0020 | avg PSNR 29.11 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 2048/2048 [10:18<00:00,  3.31it/s, it=2048/2048, loss=0.0013, avg=0.0019, psnr=29.81 dB, avg_psnr=29.33 dB, gstep=12288, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] avg loss 0.0019 | avg PSNR 29.33 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 2048/2048 [14:33<00:00,  2.34it/s, it=2048/2048, loss=0.0009, avg=0.0018, psnr=31.12 dB, avg_psnr=29.44 dB, gstep=14336, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] avg loss 0.0018 | avg PSNR 29.44 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 2048/2048 [12:21<00:00,  2.76it/s, it=2048/2048, loss=0.0011, avg=0.0019, psnr=30.12 dB, avg_psnr=29.56 dB, gstep=16384, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] avg loss 0.0019 | avg PSNR 29.56 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 2048/2048 [12:34<00:00,  2.71it/s, it=2048/2048, loss=0.0023, avg=0.0018, psnr=27.39 dB, avg_psnr=29.59 dB, gstep=18432, lr=1.00e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] avg loss 0.0018 | avg PSNR 29.59 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 2048/2048 [13:08<00:00,  2.60it/s, it=2048/2048, loss=0.0011, avg=0.0020, psnr=29.66 dB, avg_psnr=29.72 dB, gstep=20480, lr=1.00e-03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] avg loss 0.0020 | avg PSNR 29.72 dB\n",
      "Saved → edge_denoiser.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_epochs(\n",
    "    model, dl, opt, loss_fn, device,\n",
    "    epochs=2, save_path=\"edge_denoiser.pth\"\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    gstep = 0\n",
    "\n",
    "    dl_len = len(dl) if hasattr(dl, \"__len__\") else None\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_psnr = 0.0\n",
    "\n",
    "        pbar = tqdm(\n",
    "            enumerate(dl, start=0),\n",
    "            total=dl_len,\n",
    "            desc=f\"Epoch {ep+1}/{epochs}\",\n",
    "            leave=True,\n",
    "            dynamic_ncols=True\n",
    "        )\n",
    "\n",
    "        for i, (noisy, clean, _) in pbar:\n",
    "            noisy = noisy.to(device, non_blocking=True)\n",
    "            clean = clean.to(device, non_blocking=True)\n",
    "\n",
    "            pred = model(noisy)\n",
    "            loss = loss_fn(pred, clean)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_psnr = sum(psnr(pred[b], clean[b]) for b in range(pred.size(0))) / pred.size(0)\n",
    "\n",
    "            gstep += 1\n",
    "            running_loss += loss.item()\n",
    "            running_psnr += float(batch_psnr)\n",
    "\n",
    "            cur_loss = loss.item()\n",
    "            avg_loss = running_loss / (i + 1)\n",
    "            avg_psnr = running_psnr / (i + 1)\n",
    "            lr = opt.param_groups[0].get(\"lr\", None)\n",
    "\n",
    "            postfix = {\n",
    "                \"it\": f\"{i+1}/{dl_len if dl_len else '?'}\",\n",
    "                \"loss\": f\"{cur_loss:.4f}\",\n",
    "                \"avg\": f\"{avg_loss:.4f}\",\n",
    "                \"psnr\": f\"{float(batch_psnr):.2f} dB\",\n",
    "                \"avg_psnr\": f\"{avg_psnr:.2f} dB\",\n",
    "                \"gstep\": gstep,\n",
    "            }\n",
    "            if lr is not None:\n",
    "                postfix[\"lr\"] = f\"{lr:.2e}\"\n",
    "            pbar.set_postfix(postfix)\n",
    "\n",
    "        steps_done = i + 1\n",
    "        print(f\"[Epoch {ep+1}] avg loss {running_loss/max(1,steps_done):.4f} | avg PSNR {running_psnr/max(1,steps_done):.2f} dB\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Saved → {save_path}\")\n",
    "\n",
    "\n",
    "train_epochs(model, train_dl, opt, loss_fn, device, epochs=10, save_path=\"edge_denoiser.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
